% Chapter Template

\chapter{Introduction} % Main chapter title

\label{Chapter1} % Change X to a consecutive number; for referencing this chapter elsewhere, use \ref{ChapterX}

Mobile applications market is a continuous growing market. According to Statista, the number of available application, by the 2020, in the two main markets together is 4407000. The great amount of applications means that there is a vast number of users willing to download them, but also means that they can change an application, or even the platform, whenever they desire to, or when something does not fulfil their needs or expectations. Therefore, every day more and more complex applications are launch in the market as well as the users becomes more demanding. As a result, every new application or new functionality should have a good quality, they should work as expected in all different scenarios the distinct users will put them in, they have to be developed very fast and also, they have to be cheap in order to be sustainable for the company who develops them. 

The great amount, the complexity, and also the more demanding users make this commerce a very competitive one.

In order to reach users quality expectations, the frequently releases time of the market and the sustainability needed for the companies, many things have been developed, among them, automated testing. Automated testing has been of high interest for researchers and companies because it lowers the costs of production and it allows better quality products. One of the branches of automated testing is the automatic exploration tools, these tools aim to explore the application as deep as possible and find as many errors as possible. There is a plethora of exploration tools. Every year there are more of them, each one using different exploring strategies. Some of them use random inputs, others use image analysis, others a mixture of these two, and new researches are starting using AI. It is easy to think that the more deep exploration the more errors will be found, but, as will be shown in this text, that is not always the case. The number of errors detected can vary due to the exploration strategy because of the nature of the errors. Furthermore, most of this exploration tools are developed for Android applications.

Examples of the automatic exploration tools are Monkey, this tool uses a semi-random generation events strategy to explore the applications, leading to different exploration results unless the same seed is given for the generation of the random events. This tool is the default one provided by Google; Firebase Test Lab, this tools is the only one which is online. Accordingly to its documentation, it analyzes the UI of the applications and explores it simulating users events. They claim to always explore the tool in the same order. Another exploration tool is RIP, an active project inside the University of Los Andes at the research group The Software Design Lab, it explores applications using a model-based GUI testing with multiple comparison criteria. It can lead to different exploration results due to its current implementation as well as to the comparison criteria. 

For developers is important to know the difference between these tools. They need to know the tools that will match the best in the new incoming project to make a good decision. Besides, the project bugged, and application complexity among others things can also affect the decision. The information available to make the decision is most of the time based in what the tools claim to do and if the developers have enough working with more than one then they have some extra information. Though, this information is not completely reliable, it is not objective and can be slanted.


%----------------------------------------------------------------------------------------
%	SECTION 1
%----------------------------------------------------------------------------------------

\section{Problem Statement}

Accordingly to the previous section, the number of automatic exploration tools is increasing annually. Thus, with no objective information about them, developers  will need to explore new tools and compare them to find the best one. It can turns easily in spending valuable time and at the end in making the wrong decision, resulting in poor quality final products. In short, the decision of the right automatic exploration tool should be easy, quickly and rely in objective data, such as coverage reached, and number of errors found.

\section{Thesis  Goals}\label{sec:thesisGoals}

The main objective of this thesis, is to provide quantitative and qualitative information of the most widely used automatic exploration tools for Android mobile applications, to facilitate developers in the selection of the right tool that suits their needs. Under those circumstances, the next specific objectives were proposed.
		\begin{enumerate}
			\item Compare the tools by their exploration coverage 
			\item Compare the tools by the number of unique error traces discovered while exploring an application.
			\item Compare the tools using qualitative aspects such as, is the tool a open source project? Is the tool free? Is the tool allowing introduce login values? how useful is the tool report for developer to reproduce, find and fix bugs?
		\end{enumerate}

\section{Thesis contribution} \label{sec:thesisContribution}

The main contribution of this thesis is to provide developers with enough and objective information, to decide which automatic exploration tool suits their projects' needs the most, making this process easy and less time consuming.

// TODO aquí
%TODO agregar datos relacionados con las conclusiones diciendo lo que se concluyó. Por ejemplo que en la mayoría de los casos es mejor usar una herramienta que la otra y decir que a pesar de que el objetivo de la tesis no era realizar una herramienta para permitirles comparar, pues se creó una que le s va a permitir comparar comodamente las diferentes herramientas usando sus propios apks.

	
\section{Document Structure}
//TODO aquí
%TODO Hacer al final porque no se sabe la estructura antes de

