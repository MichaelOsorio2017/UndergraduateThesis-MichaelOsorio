% Chapter Template

\chapter{Introduction} % Main chapter title

\label{Chapter1} % Change X to a consecutive number; for referencing this chapter elsewhere, use \ref{ChapterX}

\MARIO{CITE Statista}
Mobile applications market is a continuous growing market. According to Statista, the number of available applications, by the 2020, in the two main markets together is 4407000. The large amount of applications means that there is a vast number of users willing to download them, but also it means that they can change an application, or even the platform, whenever they desire to, or when something does not fulfil their needs or expectations. Therefore, every day more and more complex applications are released in the market as well as the users becomes more demanding. As a result, every new application or new functionality should have a good quality, they should work as expected in all different scenarios the distinct users will put them in, they have to be developed very fast and also, they have to be cheap in order to be sustainable for the company who develops them. 

The large amount of publicly available, their complexity, and also the more demanding users make this market a very competitive one.

In order to reach users quality expectations, improve release times  and the sustainability needed for the companies, many approaches have been promoted, among them, automated testing. Automated testing has been of high interest for researchers and companies because it lowers the costs of production and it allows better quality products. One of the branches of automated testing is automatic exploration tools; these tools aim to explore  applications as deep as possible and find as many errors as possible. There is a plethora of exploration tools. Every year there are more of them, each one using different exploration strategies. Some of them use random inputs, others use image analysis, others use a mixture of these two, and new researches are starting using AI. It is easy to think that the more deep the exploration the more errors will be found, however, as will be shown in this text, that is not always the case. The number of errors detected can vary due to the exploration strategy because of the nature of the errors  and the apps. Furthermore, most of the exploration tools are developed for Android applications.

Examples of the automatic exploration tools are Monkey \footcite{https://developer.android.com/studio/test/monkey}. This tool uses a pseudo-random generation events strategy, leading to different exploration results unless the same seed is given for the generation of the random events. This tool is the default one provided by Google. Another well known tool is Firebase Test Lab \footcite{https://firebase.google.com/}; this tool can be used online. Accordingly to its documentation, it analyzes the UI of the applications and explores the apps by simulating users events. They claim to always explore the tool in the same order. Another exploration tool is RIP \MARIO{CITE. USE THE PAPER CAMILO SAID}, an active project from  The Software Design Lab at \emph{Universidad de los Andes}; RIP explores applications using a model-based GUI testing technique. It can lead to different exploration results due to its current implementation as well as to the comparison criteria. 

For developers, it  is important to know the difference between these tools. They need to know the tools that will work the best in the new incoming project to make a good decision. Besides, the project budget, and application complexity among others things can also affect the decision. The information available to make the decision is often based in what the tools claim to do. This information is not completely reliable.

Additionally, for researchers, it is also important to know what is the advantages of all the different exploration strategies, as well as their disadvantages. They need to compare them to know what is the next step to make the field go further.

%----------------------------------------------------------------------------------------
%	SECTION 1
%----------------------------------------------------------------------------------------

\section{Problem Statement}

Accordingly to the previous section, the number of automatic exploration tools is increasing annually. Thus, with no objective information about them, developers  will need to explore new tools and compare them to find the best one. It can turns easily in spending valuable time and at the end in making the wrong decision, resulting in final products with poor quality. In short, the decision of the right automatic exploration tool should be easy and rely in objective data, such as coverage reached, and number of errors found.

\section{Thesis  Goals}\label{sec:thesisGoals}

The main objective of this thesis, is to provide quantitative and qualitative information of the most widely used automatic exploration tools for Android mobile applications, to facilitate developers in the selection of the right tool that suits their needs. Under those circumstances, the following specific objectives were proposed:
		\begin{enumerate}
			\item Compare exploration tools  based on their method  coverage capabilities
			\item Compare exploration tool based on the number of unique error traces discovered while exploring an application.
		\end{enumerate}

\section{Thesis contribution} \label{sec:thesisContribution}

The main contribution of this thesis is to provide developers with enough objective information, to decide which automatic exploration tool suits the most their projects' needs, making this process easy and less time consuming.

Alongside, this study shows that higher coverage does not guaranties higher number of found errors, which, as shown later in this work, is the case of Firebase Test Lab. This tool had the highest method coverage both in average and accumulated, but it is not the best one when regarding to errors found. 

All this information provides better points of view to developers and researchers, giving fixed and objective comparison points that they can use in a decision-making situation, resulting in better projects. 

Furthermore, even when the study does not have the objective of create a reproducible work flow, it was created. New researches can use it as a base for new comparison studies, as well as extend it, and enhance it to create a new standardization of the validation of new exploration tools for Android applications. Plus, two tools for helping the validation of new exploration tools were designed InstruAPK (section \ref{sec:instruAPK}) and CoverageAnalyzer (section \ref{sec:ca}). Such tools also can be improved, adding more features and gaining more and preciser information from the explorations.
	
\section{Document Structure}

This document has the following structure: In Chapter \ref{Chapter2} related work is described, you will find information about automatic exploration tools for android applications as well as information about researches that have already made comparisons between some tools. Next chapter, Chapter \ref{Chapter3} describe the solution design which includes, the general approach (Section \ref{sec:generalApproach}) to get done the objectives described in section \ref{sec:thesisGoals}, besides a brief explanation of the tools created for this study (Sections \ref{sec:instruAPK} and \ref{sec:ca}). Now, in chapter \ref{Chapter4} you will find the empirical study, here is clarify how the data was obtained, what tools and applications were used, the devices involved in the study and other important data to reproduce the research. Additionally, in the same chapter you will find the results of the study together with their reasoning. On top of that, chapter \ref{Chapter5} describes de conclusions using the data obtained in the previous chapter. Finally, chapter \ref{Chapter6} depicts the future work, discoursing the new researches that could be made when taking this study as a base or as a reference.
