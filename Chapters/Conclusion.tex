% Chapter Template

\chapter{Conclusions and Future Work} % Main chapter title
\label{Chapter5}
% Change X to a consecutive number; for referencing this chapter elsewhere, use \ref{ChapterX}

With the results shown in sections \ref{sec:coverageResults} and \ref{sec:errorResults} there are enough data to conclude that: The best tool for reach high method coverage is Firebase Test Lab, which also is capable of finding some errors while exploring.

Nevertheless, in a testing environment, the high method coverage is not that important if no errors are found, for that reason, Monkey becomes a better option. Even when this tool has no complex architecture nor complicated exploration strategy, and is the default tool provided with Android SDK Tools. In this study is shown that the relation between method coverage reached and the number of errors found of Monkey is better than for the other tools presented in this document. 

Another conclusion for this study is that a more complex exploration strategy not always leads to better coverage and higher numbers of errors discovered.

Thus, it is visible that the main objective together with the specific objectives proposed in section \ref{sec:thesisGoals} were fulfilled within this document.
\MARIO{No se alcanzaron con el documento si no con el trabajo que se realizó y está siendo presentado en el documento} The specific objective number one was satisfied in section \ref{sec:coverageResults}, and the specific objective number two was achieved in section \ref{sec:errorResults}. The results shown in the aforementioned sections, allow developers and researcher to validate their decisions when selecting an automatic exploration tool for Android applications, as well as give them an idea of what is still missing when regarding the automatic exploration of Android applications. In consequence, the main objective was accomplished.

Furthermore, as more and more exploration tools are designed and implemented, as well as exploration strategies there is the need of repeat this research periodically owing to provide information of the newest tool to developers and researchers. This study also will allow researchers to know what are the next steps for reaching better testing tools regarding automatic exploration. 

Besides, the workflow designed for this study and detailed in section \ref{sec:generalApproach} can be refined, extended and enhanced so as to achieve the standardization of the validation of new exploration tools for Android apps. 

Additionally, because of time limitations, and resources, the number of applications used in this study was not as high as was expected at the beginning. So, in order to extend this study, more applications and different tools can be used, as well as use human exploration to compare the results of a human-being against the automatic exploration tools can be made.

Another validation that can be made, is to validate that the tools are orthogonal to each other. That means that all the methods visited by one tool were visited for the other. Could be interesting because can be the case of a tool reaching less coverage, but it visited the most complex methods, and one with high coverage but, it only reached the methods that do not present any difficulty. 

Finally, the tool designed for this study InstruAPK (\ref{sec:instruAPK}) and CoverageAnalyzer (\ref{sec:ca}) can have several improvements. InstruAPK can only instrument methods that are being called inside the source code, avoiding the instrumentation of dead code, which for now could be rising the number of instrumented methods and limiting the accuracy of the coverage reports.
